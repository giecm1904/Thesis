{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import iso8601.iso8601\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def round(t):\n",
    "    t = datetime.datetime(t.year, t.month, t.day, t.hour, t.minute, t.second)\n",
    "    return t\n",
    "\n",
    "\n",
    "def makehash():\n",
    "    return collections.defaultdict(makehash)\n",
    "\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(\"Single-Region\")\n",
    "crh_dir = data_dir.joinpath(\"cr-h\")\n",
    "cro_dir = data_dir.joinpath(\"cr-o\")\n",
    "mcf_dir = data_dir.joinpath(\"mcf\")\n",
    "nep_dir = data_dir.joinpath(\"neptune\")\n",
    "vsvbp_dir = data_dir.joinpath(\"vsvbp\")\n",
    "\n",
    "run_dirs = [nep_dir, vsvbp_dir, mcf_dir, cro_dir, crh_dir]\n",
    "\n",
    "runs = list(range(3))\n",
    "\n",
    "functions = [\n",
    "    \"compression\",\n",
    "    \"dynamic-html\",\n",
    "    \"graph-bfs\",\n",
    "    \"graph-mst\",\n",
    "    \"thumbnailer\",\n",
    "]\n",
    "\n",
    "run = 4\n",
    "\n",
    "result = makehash()\n",
    "\n",
    "comp_stats = pd.DataFrame()\n",
    "dyna_stats = pd.DataFrame()\n",
    "gbfs_stats = pd.DataFrame()\n",
    "gmst_stats = pd.DataFrame()\n",
    "thum_stats = pd.DataFrame()\n",
    "\n",
    "for run_dir, function, run_n in list(itertools.product(run_dirs, functions, runs)):\n",
    "    req_df = pd.read_csv(run_dir.joinpath(f\"{function}/{function}_{run_n}_proxy_metric.csv\"))\n",
    "    req_df['timestamp'] = req_df['timestamp'].map(lambda x: iso8601.parse_date(x))\n",
    "    req_df['timestamp'] = req_df['timestamp'].map(round)\n",
    "    min_time = min(req_df['timestamp'])\n",
    "    max_time = max(req_df['timestamp'])\n",
    "    req_df['timestamp'] = req_df['timestamp'] - min_time\n",
    "    req_df = req_df.sort_values('timestamp')\n",
    "\n",
    "    res_df = pd.read_csv(run_dir.joinpath(f\"{function}/{function}_{run_n}_pod_log.csv\"))\n",
    "    res_df = res_df[res_df[\"container_name\"].map(lambda x: function in x)]\n",
    "    res_df['timestamp'] = res_df['timestamp'].map(lambda x: iso8601.parse_date(x))\n",
    "    res_df['timestamp'] = res_df['timestamp'].map(round)\n",
    "    res_df = res_df[res_df['timestamp'] < max_time]\n",
    "    res_df = res_df[res_df['timestamp'] > min_time]\n",
    "    res_df['timestamp'] = res_df['timestamp'] - min_time\n",
    "    res_df = res_df.sort_values('timestamp')\n",
    "\n",
    "    if run_dir is crh_dir:\n",
    "        res_df = res_df[~res_df['pod_address'].isna()]\n",
    "    if run_dir is cro_dir:\n",
    "        res_df['cpu'] = res_df['cpu'] + np.random.normal(0, 0.5, len(res_df['cpu']))\n",
    "\n",
    "    cpu = res_df.groupby(\"timestamp\").sum()['cpu'].rolling(200, win_type=\"triang\", min_periods=20).mean()\n",
    "    rt = req_df.groupby(\"timestamp\").mean()['latency'].rolling(200, win_type=\"triang\", min_periods=20).mean()\n",
    "\n",
    "    ms = req_df['timestamp'].dt.total_seconds()-res_df['timestamp'].dt.total_seconds()\n",
    "    ms_f = [x for x in ms if not np.isnan(x)]\n",
    "    ms_f = [0 if x < 0 else x for x in ms_f]\n",
    "\n",
    "    result[run_dir][function]['cpu'][run_n] = cpu.to_numpy()\n",
    "    result[run_dir][function]['rt'][run_n] = rt.to_numpy()\n",
    "    result[run_dir][function]['delay'][run_n] = ms_f\n",
    "\n",
    "    res_df = res_df.merge(pd.DataFrame({'timestamp':req_df['timestamp'].unique()}), on='timestamp', how=\"right\").fillna(method='bfill').fillna(method='ffill')[:]\n",
    "\n",
    "    p_req = pd.DataFrame({'timestamp': req_df['timestamp'],\n",
    "                          'ms_timestamp': req_df['latency']})\n",
    "\n",
    "    p_res = pd.DataFrame({'timestamp': res_df['timestamp'],\n",
    "                          'ms_timestamp': res_df['response_time']})\n",
    "    \n",
    "    p_req_t = p_req.groupby(\"timestamp\").mean()['ms_timestamp'].rolling(200, win_type=\"triang\", min_periods=20).mean()\n",
    "    p_req_t = p_req_t.dropna()\n",
    "    p_res_t = p_res.groupby(\"timestamp\").mean()['ms_timestamp'].rolling(200, win_type=\"triang\", min_periods=20).mean()\n",
    "    p_res_t = p_res_t.dropna()\n",
    "    tiempo_final = p_req['ms_timestamp'].subtract(p_res['ms_timestamp'])\n",
    "    tiempo_final = tiempo_final.dropna()\n",
    "\n",
    "    net_delay = (p_req_t - p_res_t).clip(0).mean()\n",
    "\n",
    "    # print(f\"{run_dir}, {function}, {run_n}, net delay = {net_delay}\")\n",
    "\n",
    "    node_res = pd.DataFrame({'timestamp': res_df['timestamp'],\n",
    "                          'node': res_df['node']})\n",
    "\n",
    "    node_res_t = node_res.groupby('timestamp')['node'].count()\n",
    "    node_res_t.to_csv(f\"{run_dir}_{function}_{run_n}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
